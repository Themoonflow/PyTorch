{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcfed838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e949a3b",
   "metadata": {},
   "source": [
    "## 1. Create Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f128845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensor from List\n",
    "data=[[1,2,], [3,4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "751f2267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8563bf93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89ab8634",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7388c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18d2c937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensor from numpy array\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dde6cb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f959d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensor from other tensor\n",
    "x_ones = torch.ones_like(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f183f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [1, 1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b477bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb309b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_ones is tensor([[1, 1],\n",
      "        [1, 1]])\n"
     ]
    }
   ],
   "source": [
    "print(\"x_ones is {}\".format(x_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a1893c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create  Tensor with random float values.\n",
    "x_random = torch.rand_like(x_data, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d557c512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_ones is tensor([[0.4772, 0.4028],\n",
      "        [0.6572, 0.8759]])\n"
     ]
    }
   ],
   "source": [
    "print(\"x_ones is {}\".format(x_random))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d368b1e",
   "metadata": {},
   "source": [
    "#### shape is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49cadc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the shape of a tensor with 2 x 3 Metrics\n",
    "shape = (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac2eb476",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tensor = torch.rand(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7360a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4053, 0.4417, 0.1029],\n",
       "        [0.6626, 0.6670, 0.8267]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d801c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create metrics of all Ones\n",
    "ones_tensor = torch.ones(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b2fd0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59d5bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_tensor = torch.zeros(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1f0ac55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Zeros Metrics is tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"All Zeros Metrics is {zero_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7478532a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e7b973",
   "metadata": {},
   "source": [
    "## 2. Tensor Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927a6c0a",
   "metadata": {},
   "source": [
    "- Tensor Atrributes: Shape, dataType, device on which they are stored, element value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f22baf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 4-D tensor. Start from 5X6 Metrics, then there're 4 groups of 5x6 Metrics, and there are 3 groups of 4groups 5X6. \n",
    "# Total elements' number is 3X(4X(5X6))=360 \n",
    "tensor = torch.rand(3,4,5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4f826d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5, 6])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cd5891be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0afba574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8f0c8198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6831, 0.3940, 0.0569, 0.8748, 0.6891, 0.9975],\n",
       "          [0.8292, 0.2424, 0.3096, 0.9392, 0.1217, 0.6707],\n",
       "          [0.1980, 0.0153, 0.3880, 0.8006, 0.8013, 0.7956],\n",
       "          [0.5258, 0.0147, 0.1999, 0.6749, 0.8777, 0.6244],\n",
       "          [0.2291, 0.5383, 0.8475, 0.6697, 0.9765, 0.0400]],\n",
       "\n",
       "         [[0.7088, 0.5523, 0.2732, 0.7144, 0.8127, 0.0721],\n",
       "          [0.5730, 0.8539, 0.4063, 0.2356, 0.4057, 0.0279],\n",
       "          [0.8828, 0.6454, 0.7476, 0.3577, 0.5179, 0.3016],\n",
       "          [0.3324, 0.4018, 0.6731, 0.1349, 0.7267, 0.2849],\n",
       "          [0.8767, 0.1445, 0.0497, 0.4010, 0.9582, 0.5579]],\n",
       "\n",
       "         [[0.4993, 0.0707, 0.9230, 0.4674, 0.7027, 0.4468],\n",
       "          [0.4403, 0.1878, 0.3869, 0.0946, 0.3423, 0.0868],\n",
       "          [0.6983, 0.3278, 0.5055, 0.4580, 0.2891, 0.6554],\n",
       "          [0.3074, 0.1049, 0.5978, 0.8627, 0.9207, 0.9874],\n",
       "          [0.2435, 0.9396, 0.7763, 0.3451, 0.7638, 0.4266]],\n",
       "\n",
       "         [[0.3603, 0.0449, 0.4665, 0.4260, 0.8771, 0.5170],\n",
       "          [0.0713, 0.9191, 0.9445, 0.4903, 0.4510, 0.4755],\n",
       "          [0.5418, 0.9076, 0.5533, 0.7873, 0.4869, 0.0552],\n",
       "          [0.1730, 0.4433, 0.4960, 0.3769, 0.5269, 0.8950],\n",
       "          [0.6489, 0.9019, 0.3036, 0.3673, 0.5846, 0.1267]]],\n",
       "\n",
       "\n",
       "        [[[0.7593, 0.9984, 0.5543, 0.9368, 0.4840, 0.4235],\n",
       "          [0.6013, 0.5050, 0.0442, 0.3629, 0.2584, 0.1639],\n",
       "          [0.6981, 0.2474, 0.0994, 0.2243, 0.3072, 0.2446],\n",
       "          [0.8365, 0.9118, 0.9598, 0.0528, 0.9812, 0.8149],\n",
       "          [0.3031, 0.7044, 0.3948, 0.6906, 0.3597, 0.7203]],\n",
       "\n",
       "         [[0.6385, 0.1268, 0.0567, 0.9597, 0.7972, 0.2272],\n",
       "          [0.0048, 0.3691, 0.3562, 0.4726, 0.4241, 0.3120],\n",
       "          [0.2417, 0.8221, 0.6957, 0.2210, 0.7593, 0.9210],\n",
       "          [0.8913, 0.1000, 0.0725, 0.3837, 0.1681, 0.9341],\n",
       "          [0.4725, 0.1188, 0.9090, 0.4080, 0.9135, 0.3543]],\n",
       "\n",
       "         [[0.0102, 0.3808, 0.4930, 0.7386, 0.2579, 0.5688],\n",
       "          [0.1268, 0.2841, 0.4998, 0.3584, 0.4963, 0.3411],\n",
       "          [0.2378, 0.3871, 0.7643, 0.1442, 0.1867, 0.5316],\n",
       "          [0.6625, 0.9038, 0.2025, 0.4671, 0.4269, 0.8572],\n",
       "          [0.3476, 0.0227, 0.0071, 0.0440, 0.5242, 0.7728]],\n",
       "\n",
       "         [[0.7663, 0.3263, 0.5422, 0.6789, 0.5257, 0.1595],\n",
       "          [0.8675, 0.2629, 0.0938, 0.1842, 0.6418, 0.1109],\n",
       "          [0.1475, 0.2148, 0.0654, 0.2373, 0.2916, 0.7610],\n",
       "          [0.8545, 0.2020, 0.7174, 0.0907, 0.3624, 0.6576],\n",
       "          [0.9215, 0.5796, 0.4793, 0.2818, 0.2162, 0.7003]]],\n",
       "\n",
       "\n",
       "        [[[0.2358, 0.9736, 0.4922, 0.1043, 0.9151, 0.4217],\n",
       "          [0.3624, 0.1257, 0.9545, 0.2453, 0.1651, 0.3312],\n",
       "          [0.6223, 0.6280, 0.4847, 0.1054, 0.8271, 0.2313],\n",
       "          [0.2103, 0.1236, 0.3195, 0.7852, 0.9511, 0.9137],\n",
       "          [0.6174, 0.0480, 0.6673, 0.7626, 0.1545, 0.4810]],\n",
       "\n",
       "         [[0.7583, 0.5132, 0.7808, 0.6368, 0.2474, 0.0331],\n",
       "          [0.1585, 0.6594, 0.2452, 0.5072, 0.9272, 0.5120],\n",
       "          [0.1921, 0.3116, 0.9169, 0.6417, 0.4590, 0.1171],\n",
       "          [0.2100, 0.0269, 0.0042, 0.4492, 0.9347, 0.5906],\n",
       "          [0.4151, 0.1877, 0.6133, 0.0827, 0.8608, 0.2250]],\n",
       "\n",
       "         [[0.8420, 0.8068, 0.1616, 0.1927, 0.6216, 0.2456],\n",
       "          [0.9490, 0.0125, 0.8320, 0.3594, 0.9181, 0.4963],\n",
       "          [0.0804, 0.6186, 0.5499, 0.4039, 0.2157, 0.4681],\n",
       "          [0.7352, 0.3959, 0.6174, 0.2552, 0.2426, 0.3672],\n",
       "          [0.2757, 0.4363, 0.2006, 0.6036, 0.8200, 0.2549]],\n",
       "\n",
       "         [[0.6010, 0.7564, 0.2780, 0.0303, 0.6339, 0.4116],\n",
       "          [0.6793, 0.8847, 0.1518, 0.9301, 0.4057, 0.7771],\n",
       "          [0.1728, 0.6412, 0.8462, 0.9136, 0.2439, 0.1075],\n",
       "          [0.1361, 0.9223, 0.4172, 0.1701, 0.8038, 0.6203],\n",
       "          [0.6551, 0.5474, 0.5265, 0.5535, 0.6778, 0.9537]]]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10934d1c",
   "metadata": {},
   "source": [
    "## 3. Tensor Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acae047",
   "metadata": {},
   "source": [
    "- Over 100 tensor operations\n",
    "- Transposing, indexing, slicing, mathematical operations, linear algebra, random sampling.\n",
    "- [Tensor Operations](https://pytorch.org/docs/stable/torch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dd461924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move tensor from CPU to GPU if available\n",
    "# 'cuda' is used to set up and run CUDA operations. It keeps track of the currently selected GPU, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "82a2ccce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on cpu\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "print(f\"Device tensor is stored on {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "92dfdc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "39661b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on cpu\n"
     ]
    }
   ],
   "source": [
    "  print(\"Device tensor is stored on {}\".format(tensor.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6db87ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_tensor = torch.ones(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "18d61792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "84c2516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_tensor[:,1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ec1c0b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3d362b",
   "metadata": {},
   "source": [
    "### 3.1 Joint Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e8d2e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_concat_verti = torch.cat([ones_tensor, ones_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "169fb5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_concat_verti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "802d495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim -> dimention's limitaion decided by the shape: ones_tensor is a 2-D 4x4 matrics. so dim=0, 1. \n",
    "# dim=0, stack at X direction as default.\n",
    "# dim=1, stack at y direction.\n",
    "t_concat_hori = torch.cat ([ones_tensor, ones_tensor, ones_tensor], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "52c0b9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_concat_hori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "45eedb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0595a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "data = torch.rand(1, 3, 64, 64)\n",
    "labels = torch.rand(1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0f0fec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all the parameters in the network\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1ded912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "138bb03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize only the classifier\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4c5bd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add5b6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a2c9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0230,  0.0080,  0.0149, -0.0845, -0.0740, -0.0667, -0.0767, -0.0224,\n",
      "         -0.0010, -0.0006]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e82d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7e6cd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5645, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee055dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
